{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c516ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mutliple outputs in cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# cell width\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0874f6e",
   "metadata": {},
   "source": [
    "# XML Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c7116",
   "metadata": {},
   "source": [
    "The plot summaries, run through the Stanford CoreNLP pipeline (tagging, parsing, NER and coref). Each filename begins with the Wikipedia movie ID (which indexes into movie.metadata.tsv).\n",
    "\n",
    "[Paper](https://www.cs.cmu.edu/~dbamman/pubs/pdf/bamman+oconnor+smith.acl13.pdf)\n",
    "\n",
    "[Dependency glossary](https://downloads.cs.stanford.edu/nlp/software/dependencies_manual.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dccbc12",
   "metadata": {},
   "source": [
    "### Imports and data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0f2c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42306"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['10000053.xml.gz',\n",
       " '10002175.xml.gz',\n",
       " '10002779.xml.gz',\n",
       " '10003264.xml.gz',\n",
       " '10004055.xml.gz']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "PATH_IN = './XML_Dataset/'\n",
    "\n",
    "xml_gz_files = [f for f in os.listdir(PATH_IN) if f.endswith('.xml.gz')]\n",
    "len(xml_gz_files)\n",
    "xml_gz_files[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa0ab59",
   "metadata": {},
   "source": [
    "### XML file structure\n",
    "```\n",
    "sentences\n",
    "│ sentence id\n",
    "│ │ tokens\n",
    "│ │ │ token id\n",
    "│ │ │ │ word\n",
    "│ │ │ │ lemma\n",
    "│ │ │ │ char offset begin\n",
    "│ │ │ │ char offset end\n",
    "│ │ │ │ POS\n",
    "│ │ │ │ NER\n",
    "│ │ parse\n",
    "│ │ basic-dependencies\n",
    "│ │ │ dep\n",
    "│ │ │ │ governor\n",
    "│ │ │ │ dependent\n",
    "│ │ collapsed-dependencies\n",
    "│ │ │ dep\n",
    "│ │ │ │ governor\n",
    "│ │ │ │ dependent\n",
    "│ │ collapsed-ccprocessed-dependencies\n",
    "│ │ │ dep\n",
    "│ │ │ │ governor\n",
    "│ │ │ │ dependent\n",
    "```\n",
    "\n",
    "We will create three dataframes:\n",
    "- tokens: for the token data\n",
    "- parse: for the parse data\n",
    "- dependecies: for the dependencies data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb2950",
   "metadata": {},
   "source": [
    "### Parsing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c630bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    comment to parse the 42k files\n",
    "    uncomment to only parse the first file, for dev purposes\n",
    "\"\"\"\n",
    "# xml_gz_files = [xml_gz_files[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3271fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8dae11059047018aee3d468ed8faa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing xml.gz files:   0%|          | 0/42306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parses_data = []\n",
    "tokens_data = []\n",
    "dependencies_data = []\n",
    "\n",
    "for file_name in tqdm(xml_gz_files, desc='Processing xml.gz files'):\n",
    "    movie_id = file_name.replace('.xml.gz', '')\n",
    "    file_path = os.path.join(PATH_IN, file_name)\n",
    "    \n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        xml_data = f.read()\n",
    "        root = ET.fromstring(xml_data)\n",
    "\n",
    "        for sentence in root.findall('.//sentence'):\n",
    "            sentence_id = sentence.get('id')\n",
    "            if sentence_id is not None:\n",
    "                \n",
    "                # appending to df_parses\n",
    "                parse = sentence.find('parse').text if sentence.find('parse') is not None else 'N/A'\n",
    "                parses_data.append({\"movie_id\": movie_id, \"sentence_id\": sentence_id, \"parse\": parse})\n",
    "\n",
    "                # appending to df_tokens\n",
    "                for token in sentence.findall('.//tokens/token'):\n",
    "                    token_id = token.get('id')\n",
    "                    word = token.find('word').text\n",
    "                    lemma = token.find('lemma').text\n",
    "                    char_offset_begin = token.find('CharacterOffsetBegin').text\n",
    "                    char_offset_end = token.find('CharacterOffsetEnd').text\n",
    "                    pos = token.find('POS').text\n",
    "                    ner = token.find('NER').text\n",
    "                    \n",
    "                    tokens_data.append({\n",
    "                        \"movie_id\": movie_id,\n",
    "                        \"sentence_id\": sentence_id,\n",
    "                        \"token_id\": token_id,\n",
    "                        \"word\": word,\n",
    "                        \"lemma\": lemma,\n",
    "                        \"COB\": char_offset_begin,\n",
    "                        \"COE\": char_offset_end,\n",
    "                        \"POS\": pos,\n",
    "                        \"NER\": ner,\n",
    "                    })\n",
    "\n",
    "                # appending to df_dependencies\n",
    "                for dep_class, dep_xpath in [(\"basic\", \"basic-dependencies\"),\n",
    "                                             (\"collapsed\", \"collapsed-dependencies\"),\n",
    "                                             (\"collapsed-ccprocessed\", \"collapsed-ccprocessed-dependencies\")]:\n",
    "                    for dep in sentence.findall(f'.//{dep_xpath}/dep'):\n",
    "                        dep_type = dep.get('type')\n",
    "                        governor_idx = dep.find('governor').get('idx')\n",
    "                        governor_text = dep.find('governor').text\n",
    "                        dependent_idx = dep.find('dependent').get('idx')\n",
    "                        dependent_text = dep.find('dependent').text\n",
    "                        dependencies_data.append({\n",
    "                            \"movie_id\": movie_id,\n",
    "                            \"sentence_id\": sentence_id,\n",
    "                            \"dependency_class\": dep_class,\n",
    "                            \"dependency_type\": dep_type,\n",
    "                            \"governor_id\": governor_idx,\n",
    "                            \"governor_word\": governor_text,\n",
    "                            \"dependent_id\": dependent_idx,\n",
    "                            \"dependent_word\": dependent_text,\n",
    "                        })\n",
    "\n",
    "tokens_df = pd.DataFrame(tokens_data)\n",
    "dependencies_df = pd.DataFrame(dependencies_data)\n",
    "parses_df = pd.DataFrame(parses_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e13e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>COB</th>\n",
       "      <th>COE</th>\n",
       "      <th>POS</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fur</td>\n",
       "      <td>Fur</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NNP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>trapper</td>\n",
       "      <td>trapper</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NNP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Jean</td>\n",
       "      <td>Jean</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "      <td>La</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905198</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>face</td>\n",
       "      <td>face</td>\n",
       "      <td>500</td>\n",
       "      <td>504</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905199</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>reality</td>\n",
       "      <td>reality</td>\n",
       "      <td>505</td>\n",
       "      <td>512</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905200</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>more</td>\n",
       "      <td>more</td>\n",
       "      <td>513</td>\n",
       "      <td>517</td>\n",
       "      <td>RBR</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905201</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>clearly</td>\n",
       "      <td>clearly</td>\n",
       "      <td>518</td>\n",
       "      <td>525</td>\n",
       "      <td>RB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905202</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>525</td>\n",
       "      <td>526</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14905203 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id  sentence_id  token_id     word    lemma  COB  COE  POS  \\\n",
       "0         10000053            1         1      Fur      Fur    0    3  NNP   \n",
       "1         10000053            1         2  trapper  trapper    4   11  NNP   \n",
       "2         10000053            1         3     Jean     Jean   12   16  NNP   \n",
       "3         10000053            1         4       La       La   17   19  NNP   \n",
       "4         10000053            1         5        B        B   20   21  NNP   \n",
       "...            ...          ...       ...      ...      ...  ...  ...  ...   \n",
       "14905198   9999280            6        14     face     face  500  504   NN   \n",
       "14905199   9999280            6        15  reality  reality  505  512   NN   \n",
       "14905200   9999280            6        16     more     more  513  517  RBR   \n",
       "14905201   9999280            6        17  clearly  clearly  518  525   RB   \n",
       "14905202   9999280            6        18        .        .  525  526    .   \n",
       "\n",
       "             NER  \n",
       "0              O  \n",
       "1              O  \n",
       "2         PERSON  \n",
       "3         PERSON  \n",
       "4         PERSON  \n",
       "...          ...  \n",
       "14905198       O  \n",
       "14905199       O  \n",
       "14905200       O  \n",
       "14905201       O  \n",
       "14905202       O  \n",
       "\n",
       "[14905203 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "movie_id        int32\n",
       "sentence_id     int16\n",
       "token_id        int16\n",
       "word           string\n",
       "lemma          string\n",
       "COB             int16\n",
       "COE             int16\n",
       "POS            string\n",
       "NER            string\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df[\"movie_id\"] = pd.to_numeric(tokens_df[\"movie_id\"], downcast='integer')\n",
    "tokens_df[\"sentence_id\"] = pd.to_numeric(tokens_df[\"sentence_id\"], downcast='integer')\n",
    "tokens_df[\"token_id\"] = pd.to_numeric(tokens_df[\"token_id\"], downcast='integer')\n",
    "tokens_df[\"COB\"] = pd.to_numeric(tokens_df[\"COB\"], downcast='integer')\n",
    "tokens_df[\"COE\"] = pd.to_numeric(tokens_df[\"COE\"], downcast='integer')\n",
    "tokens_df[\"word\"] = tokens_df[\"word\"].astype(\"string\")\n",
    "tokens_df[\"lemma\"] = tokens_df[\"lemma\"].astype(\"string\")\n",
    "tokens_df[\"POS\"] = tokens_df[\"POS\"].astype(\"string\")\n",
    "tokens_df[\"NER\"] = tokens_df[\"NER\"].astype(\"string\")\n",
    "tokens_df\n",
    "tokens_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad716e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>dependency_class</th>\n",
       "      <th>dependency_type</th>\n",
       "      <th>governor_id</th>\n",
       "      <th>governor_word</th>\n",
       "      <th>dependent_id</th>\n",
       "      <th>dependent_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>basic</td>\n",
       "      <td>nn</td>\n",
       "      <td>6</td>\n",
       "      <td>te</td>\n",
       "      <td>1</td>\n",
       "      <td>Fur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>basic</td>\n",
       "      <td>nn</td>\n",
       "      <td>6</td>\n",
       "      <td>te</td>\n",
       "      <td>2</td>\n",
       "      <td>trapper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>basic</td>\n",
       "      <td>nn</td>\n",
       "      <td>6</td>\n",
       "      <td>te</td>\n",
       "      <td>3</td>\n",
       "      <td>Jean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>basic</td>\n",
       "      <td>nn</td>\n",
       "      <td>6</td>\n",
       "      <td>te</td>\n",
       "      <td>4</td>\n",
       "      <td>La</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>basic</td>\n",
       "      <td>nn</td>\n",
       "      <td>6</td>\n",
       "      <td>te</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34199063</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>collapsed-ccprocessed</td>\n",
       "      <td>nn</td>\n",
       "      <td>15</td>\n",
       "      <td>reality</td>\n",
       "      <td>13</td>\n",
       "      <td>Marcelo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34199064</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>collapsed-ccprocessed</td>\n",
       "      <td>nn</td>\n",
       "      <td>15</td>\n",
       "      <td>reality</td>\n",
       "      <td>14</td>\n",
       "      <td>face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34199065</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>collapsed-ccprocessed</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>17</td>\n",
       "      <td>clearly</td>\n",
       "      <td>15</td>\n",
       "      <td>reality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34199066</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>collapsed-ccprocessed</td>\n",
       "      <td>advmod</td>\n",
       "      <td>17</td>\n",
       "      <td>clearly</td>\n",
       "      <td>16</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34199067</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>collapsed-ccprocessed</td>\n",
       "      <td>xcomp</td>\n",
       "      <td>12</td>\n",
       "      <td>makes</td>\n",
       "      <td>17</td>\n",
       "      <td>clearly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34199068 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id  sentence_id       dependency_class dependency_type  \\\n",
       "0         10000053            1                  basic              nn   \n",
       "1         10000053            1                  basic              nn   \n",
       "2         10000053            1                  basic              nn   \n",
       "3         10000053            1                  basic              nn   \n",
       "4         10000053            1                  basic              nn   \n",
       "...            ...          ...                    ...             ...   \n",
       "34199063   9999280            6  collapsed-ccprocessed              nn   \n",
       "34199064   9999280            6  collapsed-ccprocessed              nn   \n",
       "34199065   9999280            6  collapsed-ccprocessed           nsubj   \n",
       "34199066   9999280            6  collapsed-ccprocessed          advmod   \n",
       "34199067   9999280            6  collapsed-ccprocessed           xcomp   \n",
       "\n",
       "          governor_id governor_word  dependent_id dependent_word  \n",
       "0                   6            te             1            Fur  \n",
       "1                   6            te             2        trapper  \n",
       "2                   6            te             3           Jean  \n",
       "3                   6            te             4             La  \n",
       "4                   6            te             5              B  \n",
       "...               ...           ...           ...            ...  \n",
       "34199063           15       reality            13        Marcelo  \n",
       "34199064           15       reality            14           face  \n",
       "34199065           17       clearly            15        reality  \n",
       "34199066           17       clearly            16           more  \n",
       "34199067           12         makes            17        clearly  \n",
       "\n",
       "[34199068 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "movie_id             int32\n",
       "sentence_id          int16\n",
       "dependency_class    string\n",
       "dependency_type     string\n",
       "governor_id          int16\n",
       "governor_word       string\n",
       "dependent_id         int16\n",
       "dependent_word      string\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependencies_df[\"movie_id\"] = pd.to_numeric(dependencies_df[\"movie_id\"], downcast='integer')\n",
    "dependencies_df[\"sentence_id\"] = pd.to_numeric(dependencies_df[\"sentence_id\"], downcast='integer')\n",
    "dependencies_df[\"governor_id\"] = pd.to_numeric(dependencies_df[\"governor_id\"], downcast='integer')\n",
    "dependencies_df[\"dependent_id\"] = pd.to_numeric(dependencies_df[\"dependent_id\"], downcast='integer')\n",
    "dependencies_df[\"dependency_class\"] = dependencies_df[\"dependency_class\"].astype(\"string\")\n",
    "dependencies_df[\"dependency_type\"] = dependencies_df[\"dependency_type\"].astype(\"string\")\n",
    "dependencies_df[\"governor_word\"] = dependencies_df[\"governor_word\"].astype(\"string\")\n",
    "dependencies_df[\"dependent_word\"] = dependencies_df[\"dependent_word\"].astype(\"string\")\n",
    "dependencies_df\n",
    "dependencies_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4da29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000053</td>\n",
       "      <td>1</td>\n",
       "      <td>(ROOT (S (NP (NNP Fur) (NNP trapper) (NNP Jean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000053</td>\n",
       "      <td>2</td>\n",
       "      <td>(ROOT (S (S (PP (IN At) (NP (DT the) (NN settl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000053</td>\n",
       "      <td>3</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN trader)) (VP (VBZ ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000053</td>\n",
       "      <td>4</td>\n",
       "      <td>(ROOT (S (ADVP (RB Later)) (, ,) (NP (DT the) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000053</td>\n",
       "      <td>5</td>\n",
       "      <td>(ROOT (S (S (NP (NNP Jean) (NNP La) (NNP B) (N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665581</th>\n",
       "      <td>9999280</td>\n",
       "      <td>2</td>\n",
       "      <td>(ROOT (S (NP (PRP He)) (VP (VBZ 's) (ADJP (JJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665582</th>\n",
       "      <td>9999280</td>\n",
       "      <td>3</td>\n",
       "      <td>(ROOT (S (NP (PRP He)) (VP (VP (VBZ lives) (PP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665583</th>\n",
       "      <td>9999280</td>\n",
       "      <td>4</td>\n",
       "      <td>(ROOT (S (NP (PRP He)) (VP (VBZ devotes) (NP (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665584</th>\n",
       "      <td>9999280</td>\n",
       "      <td>5</td>\n",
       "      <td>(ROOT (S (S (NP (PRP She)) (, ,) (ADVP (RB how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665585</th>\n",
       "      <td>9999280</td>\n",
       "      <td>6</td>\n",
       "      <td>(ROOT (S (NP (NNP Marcelo)) (ADVP (RB also)) (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665586 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        movie_id  sentence_id  \\\n",
       "0       10000053            1   \n",
       "1       10000053            2   \n",
       "2       10000053            3   \n",
       "3       10000053            4   \n",
       "4       10000053            5   \n",
       "...          ...          ...   \n",
       "665581   9999280            2   \n",
       "665582   9999280            3   \n",
       "665583   9999280            4   \n",
       "665584   9999280            5   \n",
       "665585   9999280            6   \n",
       "\n",
       "                                                    parse  \n",
       "0       (ROOT (S (NP (NNP Fur) (NNP trapper) (NNP Jean...  \n",
       "1       (ROOT (S (S (PP (IN At) (NP (DT the) (NN settl...  \n",
       "2       (ROOT (S (NP (DT The) (NN trader)) (VP (VBZ ex...  \n",
       "3       (ROOT (S (ADVP (RB Later)) (, ,) (NP (DT the) ...  \n",
       "4       (ROOT (S (S (NP (NNP Jean) (NNP La) (NNP B) (N...  \n",
       "...                                                   ...  \n",
       "665581  (ROOT (S (NP (PRP He)) (VP (VBZ 's) (ADJP (JJ ...  \n",
       "665582  (ROOT (S (NP (PRP He)) (VP (VP (VBZ lives) (PP...  \n",
       "665583  (ROOT (S (NP (PRP He)) (VP (VBZ devotes) (NP (...  \n",
       "665584  (ROOT (S (S (NP (PRP She)) (, ,) (ADVP (RB how...  \n",
       "665585  (ROOT (S (NP (NNP Marcelo)) (ADVP (RB also)) (...  \n",
       "\n",
       "[665586 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "movie_id        int32\n",
       "sentence_id     int16\n",
       "parse          string\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parses_df[\"movie_id\"] = pd.to_numeric(parses_df[\"movie_id\"], downcast='integer')\n",
    "parses_df[\"sentence_id\"] = pd.to_numeric(parses_df[\"sentence_id\"], downcast='integer')\n",
    "parses_df[\"parse\"] = parses_df[\"parse\"].astype(\"string\")\n",
    "parses_df\n",
    "parses_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1cbf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without dtype optimization (staying with int64 and string)\n",
    "# tokens_df.to_csv('tokens.csv', index=False) # 556 MB\n",
    "# dependencies_df.to_csv('dependencies.csv', index=False) # 1.5G GB\n",
    "# parses_df.to_csv('parses.csv', index=False) # 225 MB\n",
    "\n",
    "# solution: use good old pickle (could also go for feather or parquet), with dtype optimization\n",
    "tokens_df.to_pickle('tokens.pkl') # 503 MB\n",
    "dependencies_df.to_pickle('dependencies.pkl') # 1.3 GB \n",
    "parses_df.to_pickle('parses.pkl') # 229 MB\n",
    "\n",
    "tokens_df.to_feather('tokens.feather') # 406 MB\n",
    "dependencies_df.to_feather('dependencies.feather') # 763 MB\n",
    "parses_df.to_feather('parses.feather') # 88 MB\n",
    "\n",
    "tokens_df.to_parquet('tokens.parquet') # 177 MB\n",
    "dependencies_df.to_parquet('dependencies.parquet') # 224 MB\n",
    "parses_df.to_parquet('parses.parquet') # 89 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29086bd",
   "metadata": {},
   "source": [
    "# Thinking on how to save the data for all the files\n",
    "TODO:\n",
    "- check the saved files and find a way to share them\n",
    "- check how to use wiki and freebase id with wikidata\n",
    "- check for a scrapper on wikidata + IMDb or other\n",
    "- Create a notebook with all the saves, probably move the single file notebook to an exploration branch\n",
    "- create a drawboard with all the files and their columns to clearly see the merges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
